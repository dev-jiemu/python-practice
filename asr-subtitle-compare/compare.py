# ASR ëª¨ë¸ë¡œ ë½‘ì€ ìë§‰ ë°ì´í„° ë¹„êµ
# VAD Filter í¬í•¨, ë¯¸í¬í•¨ ë‘˜ë‹¤ ë¹„êµ
from difflib import SequenceMatcher
from typing import List, Tuple
from utils import parse_srt, normalize_text, calculate_wer, SRTSegment

def timeline_analysis(seg1: List[SRTSegment], seg2: List[SRTSegment], label1: str, label2: str):
    print(f"â±ï¸ íƒ€ì„ë¼ì¸ ë¶„ì„:")
    print(f"   - {label1}: {seg1[0].start_time:.3f}s ~ {seg1[-1].end_time:.3f}s")
    print(f"   - {label2}: {seg2[0].start_time:.3f}s ~ {seg2[-1].end_time:.3f}s")
    print(f"   - ì‹œì‘ ì‹œê°„ ì°¨ì´: {abs(seg1[0].start_time - seg2[0].start_time)*1000:.0f}ms")
    print(f"   - ì¢…ë£Œ ì‹œê°„ ì°¨ì´: {abs(seg1[-1].end_time - seg2[-1].end_time)*1000:.0f}ms\n")


def segment_analysis(seg1: List[SRTSegment], seg2: List[SRTSegment], label1: str, label2: str):
    avg_duration1 = sum([s.end_time - s.start_time for s in seg1]) / len(seg1)
    avg_duration2 = sum([s.end_time - s.start_time for s in seg2]) / len(seg2)

    avg_words1 = sum([len(s.text.split()) for s in seg1]) / len(seg1)
    avg_words2 = sum([len(s.text.split()) for s in seg2]) / len(seg2)

    print(f"ğŸ“‹ ì„¸ê·¸ë¨¼íŠ¸ êµ¬ì¡°:")
    print(f"   - {label1}: {len(seg1)}ê°œ ì„¸ê·¸ë¨¼íŠ¸")
    print(f"      í‰ê·  ê¸¸ì´: {avg_duration1:.2f}ì´ˆ, í‰ê·  {avg_words1:.1f} ë‹¨ì–´")
    print(f"   - {label2}: {len(seg2)}ê°œ ì„¸ê·¸ë¨¼íŠ¸")
    print(f"      í‰ê·  ê¸¸ì´: {avg_duration2:.2f}ì´ˆ, í‰ê·  {avg_words2:.1f} ë‹¨ì–´\n")

def compare_srt_files(file1: str, file2:str, label1: str, label2: str):
    segments1 = parse_srt(file1)
    segments2 = parse_srt(file2)

    # 1. ì „ì²´ í…ìŠ¤íŠ¸ ì¶”ì¶œ
    text1 = ' '.join([s.text for s in segments1])
    text2 = ' '.join([s.text for s in segments2])

    text1_norm = normalize_text(text1)
    text2_norm = normalize_text(text2)

    # 2. í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ (SequenceMatcher)
    similarity = SequenceMatcher(None, text1_norm, text2_norm).ratio()

    print(f"=== {label1} vs {label2} ===\n")
    print(f"ğŸ“Š ì „ì²´ í…ìŠ¤íŠ¸ ìœ ì‚¬ë„: {similarity * 100:.2f}%\n")

    # 3. ë‹¨ì–´ ìˆ˜ì¤€ ë¹„êµ (WER ê³„ì‚°)
    words1 = text1_norm.split()
    words2 = text2_norm.split()

    wer = calculate_wer(words1, words2)
    print(f"ğŸ“ ë‹¨ì–´ ì˜¤ë¥˜ìœ¨ (WER): {wer:.2f}%")
    print(f"   - {label1}: {len(words1)} ë‹¨ì–´")
    print(f"   - {label2}: {len(words2)} ë‹¨ì–´\n")

    # 4. íƒ€ì„ë¼ì¸ ë¹„êµ
    timeline_analysis(segments1, segments2, label1, label2)

    # 5. ì„¸ê·¸ë¨¼íŠ¸ êµ¬ì¡° ë¹„êµ
    segment_analysis(segments1, segments2, label1, label2)

    return {
        'similarity': similarity,
        'wer': wer,
        'segments_count': (len(segments1), len(segments2)),
        'words_count': (len(words1), len(words2))
    }

if __name__ == '__main__':
    diff_srt_1 = "./compare/canary.srt"
    diff_srt_1_label = "Canary"
    diff_srt_2 = "./compare/canary_filtered.srt"
    diff_srt_2_label = "Canary VAD Filter"

    _ = compare_srt_files(diff_srt_1, diff_srt_2, diff_srt_1_label, diff_srt_2_label)